{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image features exercise\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "We have seen that we can achieve reasonable performance on an image classification task by training a linear classifier on the pixels of the input image. In this exercise we will show that we can improve our classification performance by training linear classifiers not on raw pixels but on features that are computed from the raw pixels.\n",
    "\n",
    "All of your work for this exercise will be done in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Similar to previous exercises, we will load CIFAR-10 data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cs231n.features import color_histogram_hsv, hog_feature\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "  # Load the raw CIFAR-10 data\n",
    "  cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "  X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "  \n",
    "  # Subsample the data\n",
    "  mask = range(num_training, num_training + num_validation)\n",
    "  X_val = X_train[mask]\n",
    "  y_val = y_train[mask]\n",
    "  mask = range(num_training)\n",
    "  X_train = X_train[mask]\n",
    "  y_train = y_train[mask]\n",
    "  mask = range(num_test)\n",
    "  X_test = X_test[mask]\n",
    "  y_test = y_test[mask]\n",
    "\n",
    "  return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features\n",
    "For each image we will compute a Histogram of Oriented\n",
    "Gradients (HOG) as well as a color histogram using the hue channel in HSV\n",
    "color space. We form our final feature vector for each image by concatenating\n",
    "the HOG and color histogram feature vectors.\n",
    "\n",
    "Roughly speaking, HOG should capture the texture of the image while ignoring\n",
    "color information, and the color histogram represents the color of the input\n",
    "image while ignoring texture. As a result, we expect that using both together\n",
    "ought to work better than using either alone. Verifying this assumption would\n",
    "be a good thing to try for the bonus section.\n",
    "\n",
    "The `hog_feature` and `color_histogram_hsv` functions both operate on a single\n",
    "image and return a feature vector for that image. The extract_features\n",
    "function takes a set of images and a list of feature functions and evaluates\n",
    "each feature function on each image, storing the results in a matrix where\n",
    "each column is the concatenation of all feature vectors for a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done extracting features for 1000 / 49000 images\n",
      "Done extracting features for 2000 / 49000 images\n",
      "Done extracting features for 3000 / 49000 images\n",
      "Done extracting features for 4000 / 49000 images\n",
      "Done extracting features for 5000 / 49000 images\n",
      "Done extracting features for 6000 / 49000 images\n",
      "Done extracting features for 7000 / 49000 images\n",
      "Done extracting features for 8000 / 49000 images\n",
      "Done extracting features for 9000 / 49000 images\n",
      "Done extracting features for 10000 / 49000 images\n",
      "Done extracting features for 11000 / 49000 images\n",
      "Done extracting features for 12000 / 49000 images\n",
      "Done extracting features for 13000 / 49000 images\n",
      "Done extracting features for 14000 / 49000 images\n",
      "Done extracting features for 15000 / 49000 images\n",
      "Done extracting features for 16000 / 49000 images\n",
      "Done extracting features for 17000 / 49000 images\n",
      "Done extracting features for 18000 / 49000 images\n",
      "Done extracting features for 19000 / 49000 images\n",
      "Done extracting features for 20000 / 49000 images\n",
      "Done extracting features for 21000 / 49000 images\n",
      "Done extracting features for 22000 / 49000 images\n",
      "Done extracting features for 23000 / 49000 images\n",
      "Done extracting features for 24000 / 49000 images\n",
      "Done extracting features for 25000 / 49000 images\n",
      "Done extracting features for 26000 / 49000 images\n",
      "Done extracting features for 27000 / 49000 images\n",
      "Done extracting features for 28000 / 49000 images\n",
      "Done extracting features for 29000 / 49000 images\n",
      "Done extracting features for 30000 / 49000 images\n",
      "Done extracting features for 31000 / 49000 images\n",
      "Done extracting features for 32000 / 49000 images\n",
      "Done extracting features for 33000 / 49000 images\n",
      "Done extracting features for 34000 / 49000 images\n",
      "Done extracting features for 35000 / 49000 images\n",
      "Done extracting features for 36000 / 49000 images\n",
      "Done extracting features for 37000 / 49000 images\n",
      "Done extracting features for 38000 / 49000 images\n",
      "Done extracting features for 39000 / 49000 images\n",
      "Done extracting features for 40000 / 49000 images\n",
      "Done extracting features for 41000 / 49000 images\n",
      "Done extracting features for 42000 / 49000 images\n",
      "Done extracting features for 43000 / 49000 images\n",
      "Done extracting features for 44000 / 49000 images\n",
      "Done extracting features for 45000 / 49000 images\n",
      "Done extracting features for 46000 / 49000 images\n",
      "Done extracting features for 47000 / 49000 images\n",
      "Done extracting features for 48000 / 49000 images\n"
     ]
    }
   ],
   "source": [
    "from cs231n.features import *\n",
    "\n",
    "num_color_bins = 10 # Number of bins in the color histogram\n",
    "feature_fns = [hog_feature, lambda img: color_histogram_hsv(img, nbin=num_color_bins)]\n",
    "X_train_feats = extract_features(X_train, feature_fns, verbose=True)\n",
    "X_val_feats = extract_features(X_val, feature_fns)\n",
    "X_test_feats = extract_features(X_test, feature_fns)\n",
    "\n",
    "# Preprocessing: Subtract the mean feature\n",
    "mean_feat = np.mean(X_train_feats, axis=0, keepdims=True)\n",
    "X_train_feats -= mean_feat\n",
    "X_val_feats -= mean_feat\n",
    "X_test_feats -= mean_feat\n",
    "\n",
    "# Preprocessing: Divide by standard deviation. This ensures that each feature\n",
    "# has roughly the same scale.\n",
    "std_feat = np.std(X_train_feats, axis=0, keepdims=True)\n",
    "X_train_feats /= std_feat\n",
    "X_val_feats /= std_feat\n",
    "X_test_feats /= std_feat\n",
    "\n",
    "# Preprocessing: Add a bias dimension\n",
    "X_train_feats = np.hstack([X_train_feats, np.ones((X_train_feats.shape[0], 1))])\n",
    "X_val_feats = np.hstack([X_val_feats, np.ones((X_val_feats.shape[0], 1))])\n",
    "X_test_feats = np.hstack([X_test_feats, np.ones((X_test_feats.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM on features\n",
    "Using the multiclass SVM code developed earlier in the assignment, train SVMs on top of the features extracted above; this should achieve better results than training SVMs directly on top of raw pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 89.491612\n",
      "iteration 100 / 1500: loss 89.526846\n",
      "iteration 200 / 1500: loss 89.582661\n",
      "iteration 300 / 1500: loss 89.675467\n",
      "iteration 400 / 1500: loss 89.807334\n",
      "iteration 500 / 1500: loss 89.950394\n",
      "iteration 600 / 1500: loss 90.148114\n",
      "iteration 700 / 1500: loss 90.380283\n",
      "iteration 800 / 1500: loss 90.626194\n",
      "iteration 900 / 1500: loss 90.915211\n",
      "iteration 1000 / 1500: loss 91.228552\n",
      "iteration 1100 / 1500: loss 91.594047\n",
      "iteration 1200 / 1500: loss 91.969237\n",
      "iteration 1300 / 1500: loss 92.400296\n",
      "iteration 1400 / 1500: loss 92.845505\n",
      "training accuracy: 0.097571\n",
      "validation accuracy: 0.085000\n",
      "iteration 0 / 1500: loss 778.527955\n",
      "iteration 100 / 1500: loss 786.684107\n",
      "iteration 200 / 1500: loss 826.060363\n",
      "iteration 300 / 1500: loss 898.203492\n",
      "iteration 400 / 1500: loss 1006.008131\n",
      "iteration 500 / 1500: loss 1153.811897\n",
      "iteration 600 / 1500: loss 1347.521458\n",
      "iteration 700 / 1500: loss 1594.920159\n",
      "iteration 800 / 1500: loss 1905.895513\n",
      "iteration 900 / 1500: loss 2292.943034\n",
      "iteration 1000 / 1500: loss 2771.543329\n",
      "iteration 1100 / 1500: loss 3360.945318\n",
      "iteration 1200 / 1500: loss 4084.705634\n",
      "iteration 1300 / 1500: loss 4971.895479\n",
      "iteration 1400 / 1500: loss 6058.044870\n",
      "training accuracy: 0.094469\n",
      "validation accuracy: 0.095000\n",
      "iteration 0 / 1500: loss 7518.669540\n",
      "iteration 100 / 1500: loss 29555.319426\n",
      "iteration 200 / 1500: loss 212768.183811\n",
      "iteration 300 / 1500: loss 1556103.788423\n",
      "iteration 400 / 1500: loss 11384366.745154\n",
      "iteration 500 / 1500: loss 83288163.148591\n",
      "iteration 600 / 1500: loss 609337612.198455\n",
      "iteration 700 / 1500: loss 4457924697.226740\n",
      "iteration 800 / 1500: loss 32614256308.125916\n",
      "iteration 900 / 1500: loss 238606480447.204987\n",
      "iteration 1000 / 1500: loss 1745649267884.447021\n",
      "iteration 1100 / 1500: loss 12771201200643.388672\n",
      "iteration 1200 / 1500: loss 93434335955488.921875\n",
      "iteration 1300 / 1500: loss 683567269775648.125000\n",
      "iteration 1400 / 1500: loss 5000990348464163.000000\n",
      "training accuracy: 0.125898\n",
      "validation accuracy: 0.113000\n",
      "iteration 0 / 1500: loss 83.828258\n",
      "iteration 100 / 1500: loss 86.004318\n",
      "iteration 200 / 1500: loss 91.262125\n",
      "iteration 300 / 1500: loss 99.833959\n",
      "iteration 400 / 1500: loss 112.043063\n",
      "iteration 500 / 1500: loss 128.383304\n",
      "iteration 600 / 1500: loss 149.495024\n",
      "iteration 700 / 1500: loss 176.253871\n",
      "iteration 800 / 1500: loss 209.727449\n",
      "iteration 900 / 1500: loss 251.245174\n",
      "iteration 1000 / 1500: loss 302.449784\n",
      "iteration 1100 / 1500: loss 365.450017\n",
      "iteration 1200 / 1500: loss 442.718316\n",
      "iteration 1300 / 1500: loss 537.365997\n",
      "iteration 1400 / 1500: loss 653.231024\n",
      "training accuracy: 0.073061\n",
      "validation accuracy: 0.077000\n",
      "iteration 0 / 1500: loss 816.367368\n",
      "iteration 100 / 1500: loss 2934.976317\n",
      "iteration 200 / 1500: loss 21016.115494\n",
      "iteration 300 / 1500: loss 153643.434412\n",
      "iteration 400 / 1500: loss 1123993.233133\n",
      "iteration 500 / 1500: loss 8223089.476591\n",
      "iteration 600 / 1500: loss 60160180.240444\n",
      "iteration 700 / 1500: loss 440132774.283880\n",
      "iteration 800 / 1500: loss 3220018825.330330\n",
      "iteration 900 / 1500: loss 23557714111.824837\n",
      "iteration 1000 / 1500: loss 172348654233.398499\n",
      "iteration 1100 / 1500: loss 1260905823512.099854\n",
      "iteration 1200 / 1500: loss 9224809494300.621094\n",
      "iteration 1300 / 1500: loss 67488870884718.289062\n",
      "iteration 1400 / 1500: loss 493749784047570.750000\n",
      "training accuracy: 0.079551\n",
      "validation accuracy: 0.081000\n",
      "iteration 0 / 1500: loss 7561.167158\n",
      "iteration 100 / 1500: loss 736007562988.660400\n",
      "iteration 200 / 1500: loss 139771719542757326848.000000\n",
      "iteration 300 / 1500: loss 26543387041118954937166856192.000000\n",
      "iteration 400 / 1500: loss 5040729254240737156939620349244342272.000000\n",
      "iteration 500 / 1500: loss 957261082588925166581345343496958174417649664.000000\n",
      "iteration 600 / 1500: loss 181788930533890897336074049142635092933880381922344960.000000\n",
      "iteration 700 / 1500: loss 34522677110490252518056618502223121119912946028260391280181248.000000\n",
      "iteration 800 / 1500: loss 6556038540822911262775005671745633884161147501651343702521057694973952.000000\n",
      "iteration 900 / 1500: loss 1245026311580418213491453277425545424329490484982682231424675687161013536292864.000000\n",
      "iteration 1000 / 1500: loss 236437065901228435016973089441916834824114244835127382898404134282075853823374390198272.000000\n",
      "iteration 1100 / 1500: loss 44900646365473238875941302032934178386105052563950249192662071671644922475382126022272932118528.000000\n",
      "iteration 1200 / 1500: loss 8526869661288630719059883179582040286262560848034760681479937991943844333810792928187604772628270678016.000000\n",
      "iteration 1300 / 1500: loss 1619297540369342498421829094248630556120239674531506711741600845950052488530143854558906537049178442662619906048.000000\n",
      "iteration 1400 / 1500: loss 307513147075585970342624137973164319350894381629849597471067848938663054834708433938235445015733745164582625289055502336.000000\n",
      "training accuracy: 0.095857\n",
      "validation accuracy: 0.081000\n",
      "iteration 0 / 1500: loss 82.076620\n",
      "iteration 100 / 1500: loss 283.323387\n",
      "iteration 200 / 1500: loss 1981.103311\n",
      "iteration 300 / 1500: loss 14432.733624\n",
      "iteration 400 / 1500: loss 105533.282567\n",
      "iteration 500 / 1500: loss 772027.885047\n",
      "iteration 600 / 1500: loss 5648096.758470\n",
      "iteration 700 / 1500: loss 41321442.567336\n",
      "iteration 800 / 1500: loss 302308058.372229\n",
      "iteration 900 / 1500: loss 2211690341.924314\n",
      "iteration 1000 / 1500: loss 16180763631.813148\n",
      "iteration 1100 / 1500: loss 118378749838.741302\n",
      "iteration 1200 / 1500: loss 866061030460.004883\n",
      "iteration 1300 / 1500: loss 6336117914671.256836\n",
      "iteration 1400 / 1500: loss 46355151658157.843750\n",
      "training accuracy: 0.120163\n",
      "validation accuracy: 0.108000\n",
      "iteration 0 / 1500: loss 767.381478\n",
      "iteration 100 / 1500: loss 71459241863.605667\n",
      "iteration 200 / 1500: loss 13570486890219358208.000000\n",
      "iteration 300 / 1500: loss 2577107064587489749046919168.000000\n",
      "iteration 400 / 1500: loss 489406229568696036068749657252036608.000000\n",
      "iteration 500 / 1500: loss 92940825327715385259034371223215992914051072.000000\n",
      "iteration 600 / 1500: loss 17649953128323270674457986285809800986828480641499136.000000\n",
      "iteration 700 / 1500: loss 3351819228348420494652044760061734746796054654487048927313920.000000\n",
      "iteration 800 / 1500: loss 636528157204998186039294203099997368859895372324805733180961059766272.000000\n",
      "iteration 900 / 1500: loss 120880055668883401730660454846391962538523006852496517313094088463040666140672.000000\n",
      "iteration 1000 / 1500: loss 22955760390355295669380975946998268568421173484421683192602674488942764123422237655040.000000\n",
      "iteration 1100 / 1500: loss 4359420023290537572074815052776528763047961485826487909838189313218386569339121800019550666752.000000\n",
      "iteration 1200 / 1500: loss 827876864730261885497096451843689460313040117435998359813066715593093493066609021818692482768916447232.000000\n",
      "iteration 1300 / 1500: loss 157218184871820606457762565960921839110725405520884069320615660509539844520690897609636690763201099284776747008.000000\n",
      "iteration 1400 / 1500: loss 29856562862695059817075732241329874818461040559290953688072257907888079756688447396343631091249679118334739226443120640.000000\n",
      "training accuracy: 0.091388\n",
      "validation accuracy: 0.101000\n",
      "iteration 0 / 1500: loss 7739.159332\n",
      "iteration 100 / 1500: loss 6103318503194392283925172417989196308116383973444923039395348480.000000\n",
      "iteration 200 / 1500: loss 9807654699012904629362080510013733561890460078393363155254566836535301636642028968415726833036852205280039288392953343508480.000000\n",
      "iteration 300 / 1500: loss 15760293460799292888783418082675918858621919769027155176302207434770200329429259916356056157365360080571150629429147172415139664798119243928253008512981535645425039247086612594011668480.000000\n",
      "iteration 400 / 1500: loss 25325815150844569137319327598406560700974558039057486836247510345308149112868954422098823866856704669766310350211575554464940643274458324866213034382992074721039093759406550573565082930836451402030603729885490762711383708322833589672201399828480.000000\n",
      "iteration 500 / 1500: loss 40697015867762876721788720906906740851476320160280266796673979701818343463794962351886234080364029247596153320253322776089606807371579245397870739906830945824220561898827733146488580915532801984670403762141375583567449434828196913436525369256015383447275953258688733295194027766413493024393742015507988480.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cs231n\\classifiers\\linear_svm.py:116: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss += 0.5 * reg * np.sum(W * W)\n",
      "cs231n\\classifiers\\linear_svm.py:116: RuntimeWarning: overflow encountered in multiply\n",
      "  loss += 0.5 * reg * np.sum(W * W)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 600 / 1500: loss inf\n",
      "iteration 700 / 1500: loss inf\n",
      "iteration 800 / 1500: loss inf\n",
      "iteration 900 / 1500: loss inf\n",
      "iteration 1000 / 1500: loss inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cs231n\\classifiers\\linear_svm.py:117: RuntimeWarning: overflow encountered in multiply\n",
      "  dW += reg * np.abs(W)\n",
      "cs231n\\classifiers\\linear_svm.py:90: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff = scores - truescores + 1 # note delta = 1\n",
      "cs231n\\classifiers\\linear_svm.py:91: RuntimeWarning: invalid value encountered in greater\n",
      "  difftrue = (diff > 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1100 / 1500: loss inf\n",
      "iteration 1200 / 1500: loss inf\n",
      "iteration 1300 / 1500: loss inf\n",
      "iteration 1400 / 1500: loss inf\n",
      "training accuracy: 0.099898\n",
      "validation accuracy: 0.105000\n",
      "lr 1.000000e-09 reg 1.000000e+05 train accuracy: 0.097571 val accuracy: 0.085000\n",
      "lr 1.000000e-09 reg 1.000000e+06 train accuracy: 0.094469 val accuracy: 0.095000\n",
      "lr 1.000000e-09 reg 1.000000e+07 train accuracy: 0.125898 val accuracy: 0.113000\n",
      "lr 1.000000e-08 reg 1.000000e+05 train accuracy: 0.073061 val accuracy: 0.077000\n",
      "lr 1.000000e-08 reg 1.000000e+06 train accuracy: 0.079551 val accuracy: 0.081000\n",
      "lr 1.000000e-08 reg 1.000000e+07 train accuracy: 0.095857 val accuracy: 0.081000\n",
      "lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.120163 val accuracy: 0.108000\n",
      "lr 1.000000e-07 reg 1.000000e+06 train accuracy: 0.091388 val accuracy: 0.101000\n",
      "lr 1.000000e-07 reg 1.000000e+07 train accuracy: 0.099898 val accuracy: 0.105000\n",
      "best validation accuracy achieved during cross-validation: 0.113000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune the learning rate and regularization strength\n",
    "\n",
    "from cs231n.classifiers.linear_classifier import LinearSVM\n",
    "\n",
    "learning_rates = [1e-9, 1e-8, 1e-7]\n",
    "regularization_strengths = [1e-5, 1e-6, 1e-7]\n",
    "\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_svm = None\n",
    "\n",
    "pass\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained classifer in best_svm. You might also want to play          #\n",
    "# with different numbers of bins in the color histogram. If you are careful    #\n",
    "# you should be able to get accuracy of near 0.44 on the validation set.       #\n",
    "################################################################################\n",
    "\n",
    "\n",
    "lrd = learning_rates\n",
    "rgd = regularization_strengths\n",
    "for lr in lrd:\n",
    "    for rg in rgd:\n",
    "        svm = LinearSVM()\n",
    "        loss_hist = svm.train(X_train_feats, y_train, learning_rate=lr, reg=rg,\n",
    "                      num_iters=1500, batch_size=500, verbose=True)\n",
    "        y_train_pred = svm.predict(X_train_feats)\n",
    "        train_acc = np.mean(y_train == y_train_pred)\n",
    "        print 'training accuracy: %f' % (train_acc, )\n",
    "        y_val_pred = svm.predict(X_val_feats)\n",
    "        val_acc = np.mean(y_val == y_val_pred)\n",
    "        print 'validation accuracy: %f' % (val_acc, )\n",
    "        \n",
    "        results[(lr, rg)] = train_acc, val_acc\n",
    "        if best_val < val_acc :\n",
    "            best_val = val_acc\n",
    "            best_svm = svm   \n",
    "            # Print out results.\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "\n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print 'lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy)\n",
    "    \n",
    "print 'best validation accuracy achieved during cross-validation: %f' % best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000L, 155L)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate your trained SVM on the test set\n",
    "y_test_pred = best_svm.predict(X_test_feats)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# An important way to gain intuition about how an algorithm works is to\n",
    "# visualize the mistakes that it makes. In this visualization, we show examples\n",
    "# of images that are misclassified by our current system. The first column\n",
    "# shows images that our system labeled as \"plane\" but whose true label is\n",
    "# something other than \"plane\".\n",
    "\n",
    "examples_per_class = 8\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for cls, cls_name in enumerate(classes):\n",
    "    idxs = np.where((y_test != cls) & (y_test_pred == cls))[0]\n",
    "    idxs = np.random.choice(idxs, examples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt.subplot(examples_per_class, len(classes), i * len(classes) + cls + 1)\n",
    "        plt.imshow(X_test[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inline question 1:\n",
    "Describe the misclassification results that you see. Do they make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network on image features\n",
    "Earlier in this assigment we saw that training a two-layer neural network on raw pixels achieved better classification performance than linear classifiers on raw pixels. In this notebook we have seen that linear classifiers on image features outperform linear classifiers on raw pixels. \n",
    "\n",
    "For completeness, we should also try training a neural network on image features. This approach should outperform all previous approaches: you should easily be able to achieve over 55% classification accuracy on the test set; our best model achieves about 60% classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cs231n.classifiers.neural_net import TwoLayerNet\n",
    "\n",
    "input_dim = X_train_feats.shape[1]\n",
    "hidden_dim = 500\n",
    "num_classes = 10\n",
    "\n",
    "net = TwoLayerNet(input_dim, hidden_dim, num_classes)\n",
    "best_net = None\n",
    "\n",
    "################################################################################\n",
    "# TODO: Train a two-layer neural network on image features. You may want to    #\n",
    "# cross-validate various parameters as in previous sections. Store your best   #\n",
    "# model in the best_net variable.                                              #\n",
    "################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run your neural net classifier on the test set. You should be able to\n",
    "# get more than 55% accuracy.\n",
    "\n",
    "test_acc = (net.predict(X_test_feats) == y_test).mean()\n",
    "print test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Design your own features!\n",
    "\n",
    "You have seen that simple image features can improve classification performance. So far we have tried HOG and color histograms, but other types of features may be able to achieve even better classification performance.\n",
    "\n",
    "For bonus points, design and implement a new type of feature and use it for image classification on CIFAR-10. Explain how your feature works and why you expect it to be useful for image classification. Implement it in this notebook, cross-validate any hyperparameters, and compare its performance to the HOG + Color histogram baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Do something extra!\n",
    "Use the material and code we have presented in this assignment to do something interesting. Was there another question we should have asked? Did any cool ideas pop into your head as you were working on the assignment? This is your chance to show off!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
